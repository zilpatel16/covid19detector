# -*- coding: utf-8 -*-
"""PBL3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hl80EjLtqKPrd2-IIS-MdLJmKLvo6Czd
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install -q keras

import numpy as np
import matplotlib.pyplot as plt
import os
import cv2
import pickle
import numpy as np
import matplotlib.image as mpimg

import keras
import tensorflow

from tensorflow.keras.models import Model
from tensorflow.keras.utils import plot_model
from tensorflow.keras.models import Sequential
from tensorflow.keras.applications import VGG19
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout, BatchNormalization, Activation

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score, precision_score, f1_score

"""# **Data** **Path** **Definition**"""

train_path = "/content/drive/MyDrive/dataset/train"
test_path = "/content/drive/MyDrive/dataset/test"

for folder in os.listdir(train_path):
  sub_path = train_path + "/" + folder

  print(folder)
  
  
  for i in range(2):
    temp_path = os.listdir(sub_path)[i]
    temp_path = sub_path + "/" + temp_path
    img = mpimg.imread(temp_path)
    implot = plt.imshow(img)
    plt.show()

"""# **Image to Pixels**"""

def imagearray(path, size):
  data = []
  for folder in os.listdir(path):
    sub_path = path + "/" + folder

    for img in os.listdir(sub_path):
      image_path = sub_path + "/" + img
      img_arr = cv2.imread(image_path)
      img_arr = cv2.resize(img_arr, size)
      data.append(img_arr)

  return data

size=(250, 250)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# train = imagearray(train_path, size)
# test = imagearray(test_path, size)
#

"""# **Normalization**"""

x_train = np.array(train)
x_test = np.array(train)

x_train = x_train/255
x_test = x_test/255

x_train

x_test

"""# **Defining Target Variables**"""

def data_class(data_path, size, class_mode):
  datagen = ImageDataGenerator(rescale = 1./255)
  classes= datagen.flow_from_directory(data_path,
                                       target_size = size,
                                       batch_size = 32,
                                       class_mode = class_mode)
  return classes

train_class = data_class(train_path, size, "binary")
test_class = data_class(test_path, size, "binary")

y_train=train_class.classes
y_test=test_class.classes

train_class.classes

train_class.class_indices

print(y_train.shape,
      y_test.shape)

"""# VGG 19 Model"""

vgg = VGG19(input_shape = (250, 250,3), weights="imagenet", include_top = False, classes = 2)

for layer in vgg.layers:
    layer.trainable = False

x = Flatten()(vgg.output)
prediction = Dense(2 ,activation="softmax")(x)

model = Model(inputs = vgg.input, outputs = prediction)
model.summary()

plot_model(model = model, show_shapes = True)

model.compile(loss = "sparse_categorical_crossentropy",
              optimizer = "adam",
              metrics = ["accuracy"])

"""# **Image** **Augmentation**"""

train_aug = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)

"""# **Training the model**"""

history = model.fit(train_aug.flow(x_train, y_train, batch_size=32),
                    steps_per_epoch=len(x_train) / 32,
                    epochs=20)

